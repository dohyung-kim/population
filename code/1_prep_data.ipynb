{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare folders; download csv and tif files; build vrt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import wget\n",
    "import tqdm\n",
    "import glob\n",
    "from osgeo import gdal\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from hdx.utilities.easy_logging import setup_logging\n",
    "from hdx.hdx_configuration import Configuration\n",
    "from hdx.data.dataset import Dataset\n",
    "from hdx.data.organization import Organization\n",
    "from zipfile import ZipFile\n",
    "import argparse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base info\n",
    "#top_folder='/home/dohyungkim/population'\n",
    "#ISO='SGP'\n",
    "#year='2015'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Population data process 1/7: data preparation\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------')\n",
    "print('Population data process 1/7: data preparation')\n",
    "print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parser \n",
    "my_parser = argparse.ArgumentParser(description='initial input')\n",
    "my_parser.add_argument('top_folder',metavar='top_folder',type=str,help='working folder')\n",
    "my_parser.add_argument('ISO',metavar='ISO',type=str,help='3 character country iso code')\n",
    "my_parser.add_argument('year',metavar='year',type=str,help='population year')\n",
    "args = my_parser.parse_args()\n",
    "top_folder = args.top_folder\n",
    "ISO = args.ISO\n",
    "year = args.year\n",
    "if not os.path.isdir(top_folder):\n",
    "    print('The path specified does not exist')\n",
    "    sys.exit()\n",
    "#print('\\n'.join(os.listdir(top_folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download file list\n",
    "#population csv file\n",
    "pop_file='population_2000_2020'\n",
    "area_file='px_area_100m'\n",
    "sub_admin='subnational_admin_2000_2020'\n",
    "\n",
    "covar_list=('srtm_topo_100m',\n",
    "            'srtm_slope_100m',\n",
    "            'viirs_100m'+'_'+year,\n",
    "            'osm_dst_roadintersec_100m_2016',\n",
    "            'osm_dst_road_100m_2016',\n",
    "            'osm_dst_waterway_100m_2016',\n",
    "            'esaccilc_dst011_100m'+'_'+year,\n",
    "            'esaccilc_dst040_100m'+'_'+year,\n",
    "            'esaccilc_dst130_100m'+'_'+year, \n",
    "            'esaccilc_dst140_100m'+'_'+year,\n",
    "            'esaccilc_dst150_100m'+'_'+year,\n",
    "            'esaccilc_dst160_100m'+'_'+year,\n",
    "            'esaccilc_dst190_100m'+'_'+year,\n",
    "            'esaccilc_dst200_100m'+'_'+year,\n",
    "            'esaccilc_dst_water_100m_2000_2012',\n",
    "            'dst_coastline_100m_2000_2020')\n",
    "\n",
    "tif_dirs=('Topo',\n",
    "          'Slope',\n",
    "          'VIIRS',\n",
    "          'OSM/DST',\n",
    "          'OSM/DST',\n",
    "          'OSM/DST',\n",
    "          'ESA_CCI_Annual/'+year,\n",
    "          'ESA_CCI_Annual/'+year,\n",
    "          'ESA_CCI_Annual/'+year,\n",
    "          'ESA_CCI_Annual/'+year,\n",
    "          'ESA_CCI_Annual/'+year,\n",
    "          'ESA_CCI_Annual/'+year,\n",
    "          'ESA_CCI_Annual/'+year,\n",
    "          'ESA_CCI_Annual/'+year,\n",
    "          'ESA_CCI_Water/DST',\n",
    "          'Coastline/DST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up paths for files\n",
    "iso_path=os.path.join(top_folder,ISO)\n",
    "if not os.path.exists(iso_path):\n",
    "    os.mkdir(iso_path)\n",
    " \n",
    "fb_path=os.path.join(top_folder,ISO,'fb_data')\n",
    "if not os.path.exists(fb_path):\n",
    "    os.mkdir(fb_path)\n",
    "    \n",
    "wp_path=os.path.join(top_folder,ISO,'wp_data')\n",
    "if not os.path.exists(wp_path):\n",
    "    os.mkdir(wp_path)\n",
    "\n",
    "csv_path=os.path.join(wp_path,'csv')\n",
    "if not os.path.exists(csv_path):\n",
    "    os.mkdir(csv_path)\n",
    "\n",
    "tif_path=os.path.join(wp_path,'tif')\n",
    "if not os.path.exists(tif_path):\n",
    "    os.mkdir(tif_path)\n",
    "    \n",
    "shp_path=os.path.join(wp_path,'shp')\n",
    "if not os.path.exists(shp_path):\n",
    "    os.mkdir(shp_path)\n",
    "\n",
    "vrt_path=os.path.join(tif_path,'vrt_tiles')\n",
    "if not os.path.exists(vrt_path):\n",
    "    os.mkdir(vrt_path)\n",
    "\n",
    "prd_path=os.path.join(wp_path,'prd_files')\n",
    "if not os.path.exists(prd_path):\n",
    "    os.mkdir(prd_path)\n",
    "    \n",
    "fb_tile_path=os.path.join(fb_path,'fb_tiles')\n",
    "if not os.path.exists(fb_tile_path):\n",
    "    os.mkdir(fb_tile_path)\n",
    "\n",
    "out_tile_path=os.path.join(fb_path,\"out_tiles\")    \n",
    "if not os.path.exists(out_tile_path):\n",
    "    os.mkdir(out_tile_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"country_code\":[ISO],\n",
    "      \"year\":[year],\n",
    "      \"rf_accuracy\":[\"\"],\n",
    "      \"n_component\":[\"\"],\n",
    "      \"regression_accuracy\":[\"\"],\n",
    "      \"total_predicted_pop\":[\"\"],\n",
    "      \"total_census_pop\":[\"\"]}\n",
    "\n",
    "df_info=pd.DataFrame(data, columns = [\"country_code\",\n",
    "                                      \"year\",\n",
    "                                      \"rf_accuracy\",\n",
    "                                      \"n_component\",\n",
    "                                      \"regression_accuracy\",\n",
    "                                      \"total_predicted_pop\",\n",
    "                                      \"total_census_pop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info.to_pickle(os.path.join(top_folder,ISO,\"df_info.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_ftp='ftp://ftp.worldpop.org.uk/GIS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading input files\n"
     ]
    }
   ],
   "source": [
    "print('downloading input files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download census table\n",
    "link = os.path.join(wp_ftp,'Population/Global_2000_2020/CensusTables/',ISO+'_'+pop_file+'.csv')\n",
    "if not os.path.exists(os.path.join(wp_path,ISO+'_'+pop_file+'.csv')):\n",
    "    wget.download(link,wp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download subnational admin grid\n",
    "link = os.path.join(wp_ftp,'Mastergrid/Global_2000_2020',ISO,'Subnational',ISO+'_'+sub_admin+'.tif')\n",
    "if not os.path.exists(os.path.join(tif_path,ISO+'_'+sub_admin+'.tif')):\n",
    "    wget.download(link,tif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download subnational shp file\n",
    "link = os.path.join(wp_ftp,'Mastergrid/Global_2000_2020',ISO,'Subnational/Shapefile',ISO+'_subnational_2000_2020')\n",
    "if not os.path.exists(os.path.join(shp_path,ISO+'_subnation_2000_2020'+'.shp')):\n",
    "    wget.download(link+'.cpg',shp_path)\n",
    "    wget.download(link+'.dbf',shp_path)\n",
    "    wget.download(link+'.prj',shp_path)\n",
    "    wget.download(link+'.shp',shp_path)\n",
    "    wget.download(link+'.shp.xml',shp_path)\n",
    "    wget.download(link+'.shx',shp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download covar csv files\n",
    "for i in range(len(covar_list)):\n",
    "    link = os.path.join(wp_ftp,'ZonalStatistics/Global_2000_2020',ISO,'mean',ISO+'_'+covar_list[i]+'_ZS_mean.csv')\n",
    "    if not os.path.exists(os.path.join(csv_path,ISO+'_'+covar_list[i]+'_ZS_mean.csv')):\n",
    "        wget.download(link,csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download area table\n",
    "link = os.path.join(wp_ftp,'ZonalStatistics/Global_2000_2020',ISO,'sum',ISO+'_'+area_file+'_ZS_sum.csv')\n",
    "if not os.path.exists(os.path.join(csv_path,ISO+'_'+area_file+'_ZS_sum.csv')):\n",
    "    wget.download(link,csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download tif files\n",
    "tif_ftp='ftp://ftp.worldpop.org.uk/GIS/Covariates/Global_2000_2020'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(covar_list)):\n",
    "    link = os.path.join(tif_ftp,ISO,tif_dirs[i],ISO+'_'+covar_list[i]+'.tif')\n",
    "    if not os.path.exists(os.path.join(tif_path,ISO+'_'+covar_list[i]+'.tif')):\n",
    "        wget.download(link,tif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build vrt file for random forest prediction later\n",
    "tif_list=list(covar_list)\n",
    "for i in range(len(covar_list)):\n",
    "    tif_list[i] =  ISO+'_'+covar_list[i]+'.tif' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrt_options = gdal.BuildVRTOptions(separate=True)\n",
    "os.chdir(tif_path)\n",
    "vrt=gdal.BuildVRT(ISO+'_covar.vrt', tif_list, options=vrt_options)\n",
    "vrt.FlushCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download facebook popluation file\n",
    "#!pip install hdx-python-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "setup_logging()\n",
    "#if Configuration.values == None:\n",
    "Configuration.create(hdx_site='prod', user_agent='population_data'+ISO, hdx_read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgs=Organization.read_from_hdx('facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=orgs.get_datasets(ISO)\n",
    "resources=Dataset.get_all_resources(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource URL http://data.humdata.org/dataset/a9d030f7-c0be-4ecc-b0f1-9c9b30752095/resource/156e8c21-7132-4038-8464-8e903bd9fc07/download/population_sgp_2018-10-01_geotiff.zip downloaded to /home/dohyungkim/population/SGP/fb_data/population_sgp_2018-10-01_geotiff.zip1.zipped geotiff\n"
     ]
    }
   ],
   "source": [
    "for i in resources:\n",
    "    #print(i['name'])\n",
    "    if i['name'].startswith('population_'+ISO.lower()) and i['name'].endswith('geotiff.zip'):\n",
    "        url, path = i.download(folder=fb_path)\n",
    "        print('Resource URL %s downloaded to %s' % (url, path))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = ZipFile(path, 'r')\n",
    "zf.extractall(fb_path)\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading input files done!\n",
      "making tiles from tif images\n"
     ]
    }
   ],
   "source": [
    "print('downloading input files done!')\n",
    "print('making tiles from tif images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'gdal_retile.py -targetDir '\n",
    "cmd+= vrt_path\n",
    "cmd+=' '\n",
    "cmd+= os.path.join(tif_path,ISO+'_covar.vrt')\n",
    "proc = subprocess.Popen(cmd,shell=True,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "stdout,stderr=proc.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_file=glob.glob(os.path.join(fb_path,'*.tif'))[0]\n",
    "\n",
    "cmd = 'gdal_retile.py -ot float32 -ps 1024 1024 -targetDir '\n",
    "cmd+= fb_tile_path\n",
    "cmd+=' '\n",
    "cmd+= fb_file\n",
    "proc = subprocess.Popen(cmd,shell=True,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "stdout,stderr=proc.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
